{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 Reconocimiento de Patrones\n",
    "\n",
    "José Julián Camacho Hernández\n",
    "\n",
    "Leonardo Guillén Fernández"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(y_test, y_pred, training_time):\n",
    "    acc = accuracy_score(y_test, y_pred)                        # Calcular la exactitud\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')              # Calcular F1 score\n",
    "    rec = recall_score(y_test, y_pred, average='macro')         # Calcular el recall\n",
    "    prec = precision_score(y_test, y_pred, average='macro')     # Calcular la precisión\n",
    "    #auc = roc_auc_score(y_test, y_pred, average='macro')        # Calcular AUC , \"AUC\":auc\n",
    "    metrics = {\"Accuracy\":acc, \"Precision\":prec, \"Recall\":rec, \"F1 Score\":f1, \"Tiempo de entrenamiento [s]\":training_time}\n",
    "    df = pd.DataFrame(metrics, index = [0])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_image = np.zeros_like(gray)\n",
    "    for i in range(1, gray.shape[0] - 1):\n",
    "        for j in range(1, gray.shape[1] - 1):\n",
    "            binary = \"\"\n",
    "            center = gray[i, j]\n",
    "            for x, y in [(-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1)]:\n",
    "                if gray[i + x, j + y] >= center:\n",
    "                    binary += \"1\"\n",
    "                else:\n",
    "                    binary += \"0\"\n",
    "            lbp_image[i, j] = int(binary, 2)\n",
    "    return lbp_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp_arrays = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"./testi/\"\n",
    "# Iterate over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Apply LBP and store the output array\n",
    "        lbp_array = lbp(image)\n",
    "        lbp_arrays.append(lbp_array)\n",
    "        labels.append(3)\n",
    "\n",
    "\n",
    "input_folder = \"./testi2/\"\n",
    "# Iterate over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Apply LBP and store the output array\n",
    "        lbp_array = lbp(image)\n",
    "        lbp_arrays.append(lbp_array)\n",
    "        labels.append(2)\n",
    "\n",
    "    \n",
    "input_folder = \"./testi3/\"\n",
    "# Iterate over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Apply LBP and store the output array\n",
    "        lbp_array = lbp(image)\n",
    "        lbp_arrays.append(lbp_array)\n",
    "        labels.append(0)\n",
    "\n",
    "\n",
    "input_folder = \"./testi4/\"\n",
    "# Iterate over all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Read the image\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Apply LBP and store the output array\n",
    "        lbp_array = lbp(image)\n",
    "        lbp_arrays.append(lbp_array)\n",
    "        labels.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "class CustomDataset:\n",
    "    def __init__(self, lbp_tensors, labels):\n",
    "        self.lbp_tensors = lbp_tensors\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lbp_tensor = self.lbp_tensors[index]\n",
    "        label = self.labels[index]\n",
    "        return lbp_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====  Feature Engineering  =====#\n",
    "\n",
    "# Convertir las listas a numpy array de tipo uint8\n",
    "lbp_np_arrays = np.array(lbp_arrays, dtype=np.uint8)\n",
    "labels_np = np.array(labels)\n",
    "\n",
    "# Dividir los datos en train y test y estratificar\n",
    "train_lbp, test_lbp, train_labels, test_labels = train_test_split(\n",
    "    lbp_np_arrays, labels_np, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Estandarización de los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_lbp)\n",
    "scaled_data = scaler.transform(train_lbp)\n",
    "train_lbp = scaled_data\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "lbp_train_tensor = torch.from_numpy(train_lbp).float()\n",
    "lbp_test_tensor = torch.from_numpy(test_lbp).float()\n",
    "labels_train_tensor = torch.from_numpy(train_labels).float()\n",
    "labels_test_tensor = torch.from_numpy(test_labels).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.646429</td>\n",
       "      <td>0.693732</td>\n",
       "      <td>7.424655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento [s]\n",
       "0  0.868421       0.75  0.646429  0.693732                     7.424655"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instaciar modelo\n",
    "input_size = lbp_tensors.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "# Definir la función de loss y optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(lbp_train_tensor)\n",
    "\n",
    "    labels_train_long_tensor = labels_train_tensor.long()         \n",
    "    labels_train_long_tensor = labels_train_long_tensor.to(device)\n",
    "    labels_onehot = F.one_hot(labels_train_long_tensor, num_classes=output_size).float()\n",
    "\n",
    "    loss = criterion(outputs, labels_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(lbp_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(predicted, labels_test_tensor, time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
