{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 Reconocimiento de Patrones\n",
    "\n",
    "José Julián Camacho Hernández\n",
    "\n",
    "Leonardo Guillén Fernández"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import display\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(y_test, y_pred, training_time):\n",
    "    acc = accuracy_score(y_test, y_pred)                        # Calcular la exactitud\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')              # Calcular F1 score\n",
    "    rec = recall_score(y_test, y_pred, average='macro')         # Calcular el recall\n",
    "    prec = precision_score(y_test, y_pred, average='macro')     # Calcular la precisión\n",
    "    #auc = roc_auc_score(y_test, y_pred, average='macro')        # Calcular AUC , \"AUC\":auc}\n",
    "    \n",
    "    true_labels_binary = label_binarize(y_test, classes=[0,1,2,3])\n",
    "    auc = roc_auc_score(true_labels_binary, y_pred.reshape(-1, 1), average='macro')\n",
    "\n",
    "    metrics = {\"Accuracy\":acc, \"Precision\":prec, \"Recall\":rec, \"F1 Score\":f1, \"AUC\":auc, \"Tiempo de entrenamiento\":training_time}\n",
    "    df = pd.DataFrame(metrics, index = [0])\n",
    "    display(df)\n",
    "\n",
    "    ## Calcular la curva ROC\n",
    "    #fpr = dict()\n",
    "    #tpr = dict()\n",
    "    #roc_auc = dict()\n",
    "    #for i in range(4):\n",
    "    #    fpr[i], tpr[i], _ = roc_curve(true_labels_binary[:,i], y_pred[:,i])\n",
    "    #    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    #plt.figure()\n",
    "\n",
    "    #for i in range(4):\n",
    "    #    plt.plot(fpr[i], tpr[i], label='Class {}: AUC = {:.2f}'.format(i, roc_auc[i]))\n",
    "\n",
    "    #plt.plot([0, 1], [0, 1], 'k--')  # Plot the diagonal line\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title('Receiver Operating Characteristic')\n",
    "    #plt.legend(loc='lower right')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP sin feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====  Cargar y aplicar feature extractor a las imágenes  =====#\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "input_folders = [\"./testi3/\", \"./testi4/\", \"./testi2/\", \"./testi/\"]\n",
    "#input_folders = [\"./COVID-19_Radiography_Dataset/COVID/\", \"./COVID-19_Radiography_Dataset/Lung_Opacity/\",\n",
    "#                 \"./COVID-19_Radiography_Dataset/Normal/\", \"./COVID-19_Radiography_Dataset/Viral_Pneumonia/\"]\n",
    "i = 0\n",
    "for folder in input_folders:\n",
    "    input_folder = folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.convert('L')          # Convertir a escala de grises\n",
    "            image = np.array(image).flatten()   # Flatten the image\n",
    "            X.append(image)\n",
    "            y.append(i)\n",
    "    i+=1\n",
    "\n",
    "np.save(\"X.npy\", X)\n",
    "np.save(\"y.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====  Feature Engineering  =====#\n",
    "\n",
    "try:\n",
    "    X_charged = np.load(\"X.npy\")\n",
    "    y_charged = np.load(\"y.npy\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found.\")\n",
    "       \n",
    "# Convertir las listas a numpy array de tipo uint8\n",
    "X_np = np.array(X_charged, dtype=np.uint8)\n",
    "y_np = np.array(y_charged)\n",
    "\n",
    "# Dividir los datos en train y test y estratificar\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    X_np, y_np, test_size=0.2, stratify=y_np, random_state=42)\n",
    "\n",
    "# Normalización de los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_X)\n",
    "scaled_data = scaler.transform(train_X)\n",
    "train_X = scaled_data\n",
    "\n",
    "# Convertir de numpy array a PyTorch tensor\n",
    "X_train_tensor = torch.from_numpy(train_X).float()\n",
    "X_test_tensor = torch.from_numpy(test_X).float()\n",
    "y_train_tensor = torch.from_numpy(train_y).float()\n",
    "y_test_tensor = torch.from_numpy(test_y).float()\n",
    "\n",
    "# Convertir a tensores de tipo long\n",
    "y_train_long_tensor = y_train_tensor.long()         \n",
    "y_train_long_tensor = y_train_long_tensor.to(device)\n",
    "\n",
    "# Convertir a one hot\n",
    "y_onehot = F.one_hot(y_train_long_tensor, num_classes=num_classes).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes, activation):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.num_classes = num_classes\n",
    "        self.activation = activation\n",
    "        # Agregar capas ocultas\n",
    "        for i, hidden_size in enumerate(hidden_sizes):\n",
    "            if i == 0:\n",
    "                self.hidden_layers.append(nn.Linear(input_size, hidden_size))\n",
    "            else:\n",
    "                self.hidden_layers.append(nn.Linear(hidden_sizes[i-1], hidden_size))\n",
    "        # Capa de salida\n",
    "        self.output_layer = nn.Linear(hidden_sizes[-1], num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        # Pasar por capas ocultas\n",
    "        for layer in self.hidden_layers:\n",
    "            out = layer(out)\n",
    "            out = self.activation(out)\n",
    "        # Pasar por capa de salida\n",
    "        out = self.output_layer(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diseño # 1\n",
    "Capas: [81401, 128, 64, 4] | Función de activación: ReLU | α = 0.001 | epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Tiempo de entrenamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.746429</td>\n",
       "      <td>0.68125</td>\n",
       "      <td>0.686111</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>124.830823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall  F1 Score       AUC  Tiempo de entrenamiento\n",
       "0  0.703704   0.746429  0.68125  0.686111  0.108553               124.830823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados esperados:  tensor([1., 0., 0., 3., 2., 2., 0., 2., 0., 1., 3., 0., 2., 3., 1., 1., 3., 2.,\n",
      "        2., 3., 0., 0., 1., 3., 0., 2., 2.])\n",
      "Resultados obtenidos:  tensor([0, 1, 0, 3, 2, 2, 0, 2, 0, 1, 2, 0, 0, 1, 1, 1, 3, 2, 1, 3, 0, 0, 0, 1,\n",
      "        0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#=====  Instaciar modelo  =====#\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_sizes = [128, 64]       \n",
    "num_classes = len(set(y_train_tensor))   \n",
    "activation = F.relu\n",
    "model = MLP(input_size, hidden_sizes, num_classes, activation)   \n",
    "\n",
    "# Definir la función de loss con learning rate y optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(X_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(y_test_tensor, predicted, time_taken)\n",
    "print('Resultados esperados: ', y_test_tensor)\n",
    "print('Resultados obtenidos: ', predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diseño # 2\n",
    "Capas: [81401, 256, 128, 64, 4] | Función de activación: ReLU | α = 0.001 | epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>302.785814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento\n",
       "0  0.703704   0.691667  0.754167  0.703571               302.785814"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados esperados:  tensor([1., 0., 0., 3., 2., 2., 0., 2., 0., 1., 3., 0., 2., 3., 1., 1., 3., 2.,\n",
      "        2., 3., 0., 0., 1., 3., 0., 2., 2.])\n",
      "Resultados obtenidos:  tensor([0, 1, 0, 3, 2, 2, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 3, 0, 1, 3, 0, 0, 0, 3,\n",
      "        0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#=====  Instaciar modelo  =====#\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_sizes = [256, 128, 64]       \n",
    "num_classes = len(set(y_train_tensor))   \n",
    "activation = F.relu\n",
    "model = MLP(input_size, hidden_sizes, num_classes, activation)   \n",
    "\n",
    "# Definir la función de loss con learning rate y optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(X_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(predicted, y_test_tensor, time_taken)\n",
    "print('Resultados esperados: ', y_test_tensor)\n",
    "print('Resultados obtenidos: ', predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diseño # 3\n",
    "Capas: [81401, 128, 64, 4] | Función de activación: ReLU | α = 0.001 | epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Tiempo de entrenamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>0.161184</td>\n",
       "      <td>151.206025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score       AUC  Tiempo de entrenamiento\n",
       "0  0.703704   0.754167  0.691667  0.703571  0.161184               151.206025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados esperados:  tensor([1., 0., 0., 3., 2., 2., 0., 2., 0., 1., 3., 0., 2., 3., 1., 1., 3., 2.,\n",
      "        2., 3., 0., 0., 1., 3., 0., 2., 2.])\n",
      "Resultados obtenidos:  tensor([0, 1, 0, 3, 2, 2, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 3, 0, 1, 3, 0, 0, 0, 3,\n",
      "        0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#=====  Instaciar modelo  =====#\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_sizes = [150, 50]       \n",
    "num_classes = len(set(y_train_tensor))   \n",
    "activation = F.relu\n",
    "model = MLP(input_size, hidden_sizes, num_classes, activation)   \n",
    "\n",
    "# Definir la función de loss con learning rate y optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(X_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(y_test_tensor, predicted, time_taken)\n",
    "print('Resultados esperados: ', y_test_tensor)\n",
    "print('Resultados obtenidos: ', predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Tiempo de entrenamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.62963</td>\n",
       "      <td>0.695513</td>\n",
       "      <td>0.63125</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>4.094419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision   Recall  F1 Score       AUC  Tiempo de entrenamiento\n",
       "0   0.62963   0.695513  0.63125  0.557143  0.131579                 4.094419"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Obtener métricas\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m computeMetrics(y_test_tensor, predicted, time_taken)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mResultados esperados: \u001b[39m\u001b[39m'\u001b[39m, y_test_tensor)\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mResultados obtenidos: \u001b[39m\u001b[39m'\u001b[39m, predicted)\n",
      "Cell \u001b[0;32mIn[123], line 20\u001b[0m, in \u001b[0;36mcomputeMetrics\u001b[0;34m(y_test, y_pred, training_time)\u001b[0m\n\u001b[1;32m     18\u001b[0m roc_auc \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     fpr[i], tpr[i], _ \u001b[39m=\u001b[39m roc_curve(true_labels_binary[:,i], y_pred[:,i])\n\u001b[1;32m     21\u001b[0m     roc_auc[i] \u001b[39m=\u001b[39m auc(fpr[i], tpr[i])\n\u001b[1;32m     23\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "#=====  Instaciar modelo  =====#\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_sizes = [200, 50]       \n",
    "num_classes = len(set(y_train_tensor))   \n",
    "activation = F.relu\n",
    "model = MLP(input_size, hidden_sizes, num_classes, activation)   \n",
    "\n",
    "# Definir la función de loss con learning rate y optimizer\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(X_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(y_test_tensor, predicted, time_taken)\n",
    "print('Resultados esperados: ', y_test_tensor)\n",
    "print('Resultados obtenidos: ', predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP con feature extractor LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====  Feature Extractor  =====#\n",
    "def lbp(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_image = np.zeros_like(gray)\n",
    "    for i in range(1, gray.shape[0] - 1):\n",
    "        for j in range(1, gray.shape[1] - 1):\n",
    "            binary = \"\"\n",
    "            center = gray[i, j]\n",
    "            for x, y in [(-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1)]:\n",
    "                if gray[i + x, j + y] >= center:\n",
    "                    binary += \"1\"\n",
    "                else:\n",
    "                    binary += \"0\"\n",
    "            lbp_image[i, j] = int(binary, 2)\n",
    "    return lbp_image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====  Cargar y aplicar feature extractor a las imágenes  =====#\n",
    "lbp_arrays = []\n",
    "lbp_labels = []\n",
    "\n",
    "input_folders = [\"./testi3/\", \"./testi4/\", \"./testi2/\", \"./testi/\"]\n",
    "#input_folders = [\"./COVID-19_Radiography_Dataset/COVID/\", \"./COVID-19_Radiography_Dataset/Lung_Opacity/\",\n",
    "#                 \"./COVID-19_Radiography_Dataset/Normal/\", \"./COVID-19_Radiography_Dataset/Viral_Pneumonia/\"]\n",
    "i = 0\n",
    "for folder in input_folders:\n",
    "    input_folder = folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            lbp_array = lbp(image)\n",
    "            lbp_arrays.append(lbp_array)\n",
    "            lbp_labels.append(i)\n",
    "    i+=1\n",
    "\n",
    "np.save(\"lbp_arrays.npy\", lbp_arrays)\n",
    "np.save(\"lbp_labels.npy\", lbp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "#=====  Feature Engineering  =====#\n",
    "\n",
    "try:\n",
    "    lbp_arrays_charged = np.load(\"lbp_arrays.npy\")\n",
    "    labels_charged = np.load(\"lbp_labels.npy\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found.\")\n",
    "    \n",
    "print(lbp_arrays_charged)    \n",
    "print(labels_charged)    \n",
    "# Convertir las listas a numpy array de tipo uint8\n",
    "lbp_np_arrays = np.array(lbp_arrays_charged, dtype=np.uint8)\n",
    "labels_np = np.array(labels_charged)\n",
    "\n",
    "# Dividir los datos en train y test y estratificar\n",
    "train_lbp, test_lbp, train_labels, test_labels = train_test_split(\n",
    "    lbp_np_arrays, labels_np, test_size=0.2, stratify=labels_np, random_state=42)\n",
    "\n",
    "# Normalización de los datos\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_lbp)\n",
    "scaled_data = scaler.transform(train_lbp)\n",
    "train_lbp = scaled_data\n",
    "\n",
    "# Convertir de numpy array a PyTorch tensor\n",
    "lbp_train_tensor = torch.from_numpy(train_lbp).float()\n",
    "lbp_test_tensor = torch.from_numpy(test_lbp).float()\n",
    "labels_train_tensor = torch.from_numpy(train_labels).float()\n",
    "labels_test_tensor = torch.from_numpy(test_labels).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.73953</td>\n",
       "      <td>67.009742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento\n",
       "0  0.777778    0.75625  0.783333   0.73953                67.009742"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados esperados:  tensor([1., 0., 0., 3., 2., 2., 0., 2., 0., 1., 3., 0., 2., 3., 1., 1., 3., 2.,\n",
      "        2., 3., 0., 0., 1., 3., 0., 2., 2.])\n",
      "Resultados obtenidos:  tensor([0, 0, 0, 3, 2, 2, 0, 2, 0, 1, 3, 0, 3, 3, 1, 3, 3, 2, 1, 3, 0, 0, 0, 3,\n",
      "        0, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Instaciar modelo\n",
    "input_size = lbp_train_tensor.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "# Definir la función de loss y optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "start_time = time.time()\n",
    "# Entrenar el modelo\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(lbp_train_tensor)\n",
    "\n",
    "    labels_train_long_tensor = labels_train_tensor.long()         \n",
    "    labels_train_long_tensor = labels_train_long_tensor.to(device)\n",
    "    labels_onehot = F.one_hot(labels_train_long_tensor, num_classes=output_size).float()\n",
    "\n",
    "    loss = criterion(outputs, labels_onehot)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Evaluate the model\n",
    "outputs = model(lbp_test_tensor)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Obtener métricas\n",
    "computeMetrics(y_test_tensor, predicted, time_taken)\n",
    "print('Resultados esperados: ', labels_test_tensor)\n",
    "print('Resultados obtenidos: ', predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
