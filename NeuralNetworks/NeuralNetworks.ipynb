{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "José Julián Camacho Hernández\n",
    "\n",
    "Leonardo Guillén Fernández"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el set de datos MNIST\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Combinar sets de training y test para estratificarlos después\n",
    "combined_images = np.concatenate((X_train, X_test), axis=0)\n",
    "combined_labels = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Descartar pixeles en los bordes\n",
    "combined_images = combined_images[:, 3:-3, 5:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seleccionar dato random del dataset\n",
    "index = np.random.randint(0, len(combined_images))\n",
    "image = combined_images[index]\n",
    "\n",
    "# Visualizar la imagen\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {combined_labels[index]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== Feature Engineering ===#\n",
    "\n",
    "# Stratified train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_images, combined_labels, test_size=0.2, stratify=combined_labels)\n",
    "\n",
    "# Reshape para pasarlas a 1D\n",
    "X_train = X_train.reshape(-1, 22*18)\n",
    "X_test = X_test.reshape(-1, 22*18)\n",
    "\n",
    "# Normalización de los datos\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_Multicapa:\n",
    "    def __init__(self, capas, alpha=0.1):\n",
    "        self.capas = capas\n",
    "        self.alpha = alpha\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        for i in range(0, len(capas) - 1):\n",
    "            # Inicializar los pesos y bias de cada capa\n",
    "            peso = np.random.randn(capas[i], capas[i+1])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.random.randn(capas[i+1])\n",
    "            self.bias.append(bias)\n",
    "\n",
    "    def activacion(self, x):\n",
    "        # Función de activación sigmoide\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "    def activacion_derivada(self, x):\n",
    "        # Derivada de la función de activación sigmoide\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Calcular la salida de cada capa\n",
    "        capa_activacion = [X]\n",
    "        for i in range(0, len(self.capas) - 1):\n",
    "            x = np.dot(capa_activacion[i], self.pesos[i]) + self.bias[i]\n",
    "            y = self.activacion(x)\n",
    "            capa_activacion.append(y)\n",
    "        return capa_activacion\n",
    "\n",
    "    def backpropagation(self, X, y, capa_activacion):\n",
    "        # Calcular el error de la capa de salida\n",
    "        error = capa_activacion[-1] - y\n",
    "        delta = error * self.activacion_derivada(capa_activacion[-1])\n",
    "\n",
    "        # Propagar el error hacia atrás a través de la red neuronal\n",
    "        for i in reversed(range(0, len(self.capas) - 1)):\n",
    "            activacion_actual = capa_activacion[i]\n",
    "            activacion_anterior = capa_activacion[i-1] if i > 0 else X\n",
    "            d_peso = np.outer(activacion_actual, delta)\n",
    "            d_bias = delta\n",
    "            self.pesos[i] -= self.alpha * d_peso\n",
    "            self.bias[i] -= self.alpha * d_bias\n",
    "            delta = np.dot(delta, self.pesos[i].T) * self.activacion_derivada(activacion_actual)\n",
    "\n",
    "    def entrenar(self, X, y, epochs):\n",
    "        for epoch in range(0, epochs):\n",
    "            for i in range(0, len(X)):\n",
    "                # Feedforward\n",
    "                capa_activacion = self.feedforward(X[i])\n",
    "\n",
    "                # Backpropagation\n",
    "                self.backpropagation(X[i], y[i], capa_activacion)\n",
    "\n",
    "    def predecir(self, X):\n",
    "        # Obtener la salida de la última capa\n",
    "        capa_activacion = self.feedforward(X)\n",
    "        return capa_activacion[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMetrics(y_test, y_pred, training_time):\n",
    "    acc = accuracy_score(y_test, y_pred)                        # Calcular la exactitud\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')              # Calcular F1 score\n",
    "    rec = recall_score(y_test, y_pred, average='macro')         # Calcular el recall\n",
    "    prec = precision_score(y_test, y_pred, average='macro')     # Calcular la precisión\n",
    "    metrics = {\"Accuracy\":acc, \"Precision\":prec, \"Recall\":rec, \"F1 Score\":f1, \"Tiempo de entrenamiento [s]\":training_time}\n",
    "    df = pd.DataFrame(metrics, index = [0])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926929</td>\n",
       "      <td>0.92704</td>\n",
       "      <td>0.925349</td>\n",
       "      <td>0.925434</td>\n",
       "      <td>85.230033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento [s]\n",
       "0  0.926929    0.92704  0.925349  0.925434                    85.230033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear y entrenar el perceptrón multicapa\n",
    "perceptron = Perceptron_Multicapa(capas=[396, 64, 10], alpha=0.15)\n",
    "\n",
    "#Tomar tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "perceptron.entrenar(X_train, np.eye(10)[y_train], epochs=5)\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Hacer predicciones sobre el conjunto de prueba\n",
    "predicciones = []\n",
    "for i in range(len(X_test)):\n",
    "    prediccion = perceptron.predecir(X_test[i])\n",
    "    prediccion_clase = np.argmax(prediccion)\n",
    "    predicciones.append(prediccion_clase)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "computeMetrics(y_test, predicciones, time_taken)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron_Multicapa_Multifuncion:\n",
    "    def __init__(self, capa_entrada, capas, capa_salida, funciones, alpha=0.1):\n",
    "        self.capas = capas\n",
    "        self.capa_entrada = capa_entrada\n",
    "        self.capa_salida = capa_salida\n",
    "        # Se agregan capas de entrada y de salida\n",
    "        self.capas.insert(0, self.capa_entrada)\n",
    "        self.capas.append(self.capa_salida)\n",
    "        self.funciones = funciones\n",
    "        self.funciones.insert(0, 'sigmoid')\n",
    "        self.funciones.append('softmax')\n",
    "        self.alpha = alpha\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        # Se elige la función de activación y su derivada por medio de diccionarios\n",
    "        self.activation_function_dict = {\n",
    "            'sigmoid': self.activacion_sigmoid,\n",
    "            'tanh': self.activacion_tanh,\n",
    "            'relu': self.activacion_relu,\n",
    "            'softmax': self.activacion_softmax\n",
    "        }\n",
    "        self.derivate_function_dict = {\n",
    "            'sigmoid': self.activacion_derivada_sigmoid,\n",
    "            'tanh': self.activacion_derivada_tanh,\n",
    "            'relu': self.activacion_derivada_relu,\n",
    "            'softmax': self.activacion_derivada_softmax\n",
    "        }\n",
    "        for i in range(0, len(capas) - 1):\n",
    "            # Inicializar los pesos y bias de cada capa\n",
    "            peso = np.random.randn(capas[i], capas[i+1])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.random.randn(capas[i+1])\n",
    "            self.bias.append(bias)\n",
    "\n",
    "    def activacion_softmax(self, x):\n",
    "        exps = np.exp(x - np.max(x))\n",
    "        return exps / np.sum(exps)\n",
    "    \n",
    "    def activacion_derivada_softmax(self, x):\n",
    "        s = self.activacion_softmax(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def activacion_sigmoid(self, x):\n",
    "        # Función de activación sigmoide\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "    def activacion_derivada_sigmoid(self, x):\n",
    "        # Derivada de la función de activación sigmoide\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def activacion_tanh(self, x):\n",
    "        # Función de activación tanh\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def activacion_derivada_tanh(self, x):\n",
    "        # Derivada de la función de activación tanh\n",
    "        return (1 - x**2)\n",
    "    \n",
    "    def activacion_relu(self, x):\n",
    "        # Función de activación ReLU\n",
    "        return np.maximum(0, x)\n",
    "        \n",
    "    def activacion_derivada_relu(self, x):\n",
    "        # Derivada de la función de activación ReLU\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        # Calcular la salida de cada capa\n",
    "        capa_activacion = [X]\n",
    "        for i in range(0, len(self.capas) - 1):\n",
    "            #print('capa_activacion[i]', capa_activacion[i].shape)\n",
    "            #print('self.pesos[i]', self.pesos[i].shape)\n",
    "            x = np.dot(capa_activacion[i], self.pesos[i]) + self.bias[i]\n",
    "            y = self.activation_function_dict.get(self.funciones[i], lambda: None)(x)\n",
    "            capa_activacion.append(y)\n",
    "        return capa_activacion\n",
    "\n",
    "    def backpropagation(self, X, y, capa_activacion):\n",
    "        # Calcular el error de la capa de salida\n",
    "        error = capa_activacion[-1] - y\n",
    "        delta = error * self.derivate_function_dict.get(self.funciones[-1], lambda: None)(capa_activacion[-1])\n",
    "        #delta = error * self.activacion_derivada_relu(capa_activacion[-1])\n",
    "        # Propagar el error hacia atrás a través de la red neuronal\n",
    "        for i in reversed(range(0, len(self.capas) - 1)):\n",
    "            activacion_actual = capa_activacion[i]\n",
    "            activacion_anterior = capa_activacion[i-1] if i > 0 else X\n",
    "            d_peso = np.outer(activacion_actual, delta)\n",
    "            d_bias = delta\n",
    "            self.pesos[i] -= self.alpha * d_peso\n",
    "            self.bias[i] -= self.alpha * d_bias\n",
    "            # Se elige la derivada de la función de activación correspondiente a la capa\n",
    "            delta = np.dot(delta, self.pesos[i].T) * self.derivate_function_dict.get(self.funciones[i], lambda: None)(activacion_actual)\n",
    "\n",
    "    def entrenar(self, X, y, epochs):\n",
    "        for epoch in range(0, epochs):\n",
    "            for i in range(0, len(X)):\n",
    "                # Feedforward\n",
    "                capa_activacion = self.feedforward(X[i])\n",
    "\n",
    "                # Backpropagation\n",
    "                self.backpropagation(X[i], y[i], capa_activacion)\n",
    "\n",
    "    def predecir(self, X):\n",
    "        # Obtener la salida de la última capa\n",
    "        capa_activacion = self.feedforward(X)\n",
    "        return capa_activacion[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859929</td>\n",
       "      <td>0.866892</td>\n",
       "      <td>0.858943</td>\n",
       "      <td>0.859621</td>\n",
       "      <td>56.549611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento [s]\n",
       "0  0.859929   0.866892  0.858943  0.859621                    56.549611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 8 4 ... 3 1 3]\n",
      "[7, 8, 4]\n"
     ]
    }
   ],
   "source": [
    "def MLP_Functions(capa_entrada, capas, capa_salida, funciones, alpha, epochs):\n",
    "\n",
    "    # Crear y entrenar el perceptrón multicapa\n",
    "    perceptron = Perceptron_Multicapa_Multifuncion(capa_entrada=capa_entrada, capas=capas, \n",
    "        capa_salida=capa_salida, funciones=funciones, alpha=alpha)\n",
    "\n",
    "    #Tomar tiempo de entrenamiento\n",
    "    start_time = time.time()\n",
    "    perceptron.entrenar(X_train, np.eye(10)[y_train], epochs=epochs)\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "\n",
    "    # Hacer predicciones sobre el conjunto de prueba\n",
    "    predicciones = []\n",
    "    for i in range(len(X_test)):\n",
    "        prediccion = perceptron.predecir(X_test[i])\n",
    "        prediccion_clase = np.argmax(prediccion)\n",
    "        predicciones.append(prediccion_clase)\n",
    "\n",
    "    # Calcular la precisión de las predicciones\n",
    "    computeMetrics(y_test, predicciones, time_taken)\n",
    "    print(y_test)\n",
    "    print(predicciones[:3])\n",
    "\n",
    "# Llamar función\n",
    "# Definir red con capas:    396 -  8  -  10  -  30  -   10\n",
    "# Funciones en las capas:   sgm - sgm - sgm  - tanh - softmax\n",
    "MLP_Functions(396, [8, 10, 30], 10, ['sigmoid', 'sigmoid', 'tanh'] , 0.125, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se dan para capas ocultas con funciones de activación sigmoid y tanh, y con capa final con softmax.\n",
    "Con relu no se obtienen buenos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Tiempo de entrenamiento [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.905857</td>\n",
       "      <td>0.904673</td>\n",
       "      <td>0.904344</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>44.819567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score  Tiempo de entrenamiento [s]\n",
       "0  0.905857   0.904673  0.904344    0.9044                    44.819567"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 0.9058571428571428\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convertir los datos a tensores de PyTorch\n",
    "X_entrenamiento = torch.Tensor(X_train)\n",
    "X_prueba = torch.Tensor(X_test)\n",
    "y_entrenamiento = torch.Tensor(y_train).long()\n",
    "y_prueba = torch.Tensor(y_test).long()\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(396, 8)    # Capa oculta 1\n",
    "        self.fc2 = nn.Linear(8, 10)     # Capa oculta 2\n",
    "        self.fc3 = nn.Linear(10, 30)    # Capa oculta 3\n",
    "        self.fc4 = nn.Linear(30, 10)    # Capa de salida\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))     # Función de activación ReLU en la capa oculta 1\n",
    "        x = torch.tanh(self.fc2(x))     # Función de activación tanh en la capa oculta 2\n",
    "        x = torch.sigmoid(self.fc3(x))  # Función de activación tanh en la capa oculta 3\n",
    "        x = self.fc4(x)                 # Capa de salida sin función de activación\n",
    "        return x\n",
    "\n",
    "# Crear el modelo de la red neuronal\n",
    "modelo = Net()\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterio = nn.CrossEntropyLoss()\n",
    "optimizador = optim.Adam(modelo.parameters())\n",
    "\n",
    "# Entrenar la red neuronal\n",
    "num_epochs = 1000\n",
    "#Tomar tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # Paso de entrenamiento\n",
    "    optimizador.zero_grad()\n",
    "    salida = modelo(X_entrenamiento)\n",
    "    perdida = criterio(salida, y_entrenamiento)\n",
    "    perdida.backward()\n",
    "    optimizador.step()\n",
    "end_time = time.time()\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Hacer predicciones sobre los datos de prueba\n",
    "with torch.no_grad():\n",
    "    salida = modelo(X_prueba)\n",
    "    _, predicciones = torch.max(salida, 1)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "precision = accuracy_score(y_prueba, predicciones)\n",
    "\n",
    "computeMetrics(y_prueba, predicciones, time_taken)\n",
    "print(\"Precisión:\", precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación de los resultados\n",
    "\n",
    "Se logra concluir que los mejores resultados se obtienen al realizar el feature engineering y quitar los bordes en color negro de las imágenes, ya que no aportan información relevante al modelo.\n",
    "\n",
    "Para el perceptrón multicapa con distintas funciones de activación, se obtuvo que los mejores resultados se dan al aplicar la función sigmoid en la mayoría de sus capas y softmax en la última.\n",
    "\n",
    "En comparación con Sklearn, se logró notar que este alcanza unas mejores métricas en general y necesita considerablemente menos tiempo de entrenamiento, debido a sus optimizaciones matemáticas, ya que hace muchas más epochs en menos tiempo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
